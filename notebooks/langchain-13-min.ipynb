{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitmetrics/langchain-13-min/blob/main/notebooks/langchain-13-min.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "50dvxjqCFmhF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load environment variables\n",
        "\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C7RnyUOCJWmk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Large language models are advanced artificial intelligence systems designed to understand, generate, and process human language by leveraging vast amounts of textual data and complex algorithms.\n"
          ]
        }
      ],
      "source": [
        "# Run basic query with OpenAI wrapper\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Use ChatOpenAI instead of OpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")  # Note: gpt-5 might not be available yet in all APIs\n",
        "response = llm.invoke([HumanMessage(content=\"explain large language models in one sentence\")])\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JtHgQ5XpJmgi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To train a neural network on simulated data, we can use popular libraries such as NumPy for data generation and TensorFlow/Keras for building and training the neural network. Below is a simple example of how you can create a dataset, build a neural network, and train it using Keras.\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "import tensorflow as tf\n",
            "from tensorflow.keras.models import Sequential\n",
            "from tensorflow.keras.layers import Dense\n",
            "from sklearn.model_selection import train_test_split\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Simulate some data\n",
            "def generate_data(num_samples=1000):\n",
            "    # Generate random input data\n",
            "    X = np.random.rand(num_samples, 2)\n",
            "    # Define a simple linear relationship with some noise\n",
            "    y = (3 * X[:, 0] + 2 * X[:, 1] + np.random.randn(num_samples) * 0.1).reshape(-1, 1)\n",
            "    return X, y\n",
            "\n",
            "# Generate data\n",
            "X, y = generate_data()\n",
            "\n",
            "# Split the data into training and testing sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "\n",
            "# Build a simple neural network model\n",
            "model = Sequential([\n",
            "    Dense(64, input_dim=2, activation='relu'),\n",
            "    Dense(32, activation='relu'),\n",
            "    Dense(1, activation='linear')\n",
            "])\n",
            "\n",
            "# Compile the model\n",
            "model.compile(optimizer='adam', loss='mean_squared_error')\n",
            "\n",
            "# Train the model\n",
            "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
            "\n",
            "# Evaluate the model on the test set\n",
            "loss = model.evaluate(X_test, y_test)\n",
            "print(f'Test Loss: {loss}')\n",
            "\n",
            "# Plot training & validation loss values\n",
            "plt.plot(history.history['loss'])\n",
            "plt.plot(history.history['val_loss'])\n",
            "plt.title('Model loss')\n",
            "plt.ylabel('Loss')\n",
            "plt.xlabel('Epoch')\n",
            "plt.legend(['Train', 'Validation'], loc='upper right')\n",
            "plt.show()\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "1. **Data Generation**: We simulate a dataset with two input features and a target variable that is a linear combination of the inputs with some added noise.\n",
            "2. **Data Splitting**: We split the data into training and testing sets using `train_test_split` from `sklearn`.\n",
            "3. **Model Building**: We build a simple feedforward neural network with two hidden layers using Keras. The first hidden layer has 64 neurons, and the second has 32 neurons, both using ReLU activation functions. The output layer has one neuron with a linear activation function to predict the target value.\n",
            "4. **Model Compilation**: We compile the model using the Adam optimizer and mean squared error as the loss function.\n",
            "5. **Model Training**: We train the model on the training data for 50 epochs with a batch size of 32 and a validation split of 20%.\n",
            "6. **Model Evaluation**: We evaluate the model on the test set and print the test loss.\n",
            "7. **Plotting**: We plot the training and validation loss over the epochs to visualize the model's learning process.\n",
            "\n",
            "This script provides a basic framework for training a neural network on simulated data. You can modify the data generation process, model architecture, and training parameters to suit your specific needs.\n"
          ]
        }
      ],
      "source": [
        "# import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-4o\",temperature=0.3)\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert data scientist\"),\n",
        "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
        "]\n",
        "response=chat.invoke(messages)\n",
        "\n",
        "print(response.content,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2grf7I8AJ_hK"
      },
      "outputs": [],
      "source": [
        "# Import prompt and define PromptTemplate\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "You are an expert data scientist with an expertise in building deep learning models. \n",
        "Explain the concept of {concept} in a couple of lines\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vcz7Q9Y-KFvI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An autoencoder is a type of artificial neural network used to learn efficient, compressed representations of data, often for the purpose of dimensionality reduction or denoising. It consists of an encoder that maps input data to a latent space and a decoder that reconstructs the original data from this compressed representation, with the goal of minimizing the reconstruction error.\n"
          ]
        }
      ],
      "source": [
        "# Run LLM with PromptTemplate\n",
        "chain = prompt | llm\n",
        "response = chain.invoke({\"concept\": \"autoencoder\"})\n",
        "print(response.content)\n",
        "# old deprecated: llm(prompt.format(concept=\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "B6MF4-nMKul3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Alright, imagine you have a big box of colorful building blocks, and you want to build a castle. But instead of just grabbing blocks at random, you have a magical map that shows you which blocks go best together, and how they fit to make the castle look just right. Now, let\\'s talk about how we use this magical idea when we want to learn things and find answers - this is where graphRAG comes in.\\n\\nThink about graphRAG as a smart helper that loves to play with ideas and connect them, just like you connect building blocks. When you have a question or need help with something, graphRAG doesn’t just look for one single block - or piece of information. Instead, it finds the coolest way to put many pieces together, so your answer is really good and makes sense, just like building a perfect tower or castle.\\n\\nHere’s the fun part: Imagine every building block has a picture on it. Some blocks have pictures of trees, others have dragons, knights, or stars. Each picture is like a piece of information or an idea. When these ideas have something in common, or a story that links them together, it’s like when two blocks have matching sides so they snap together just right. GraphRAG knows all the best tricks to find which blocks should snap together to make your answer strong and clear.\\n\\nThe \"graph\" part in graphRAG is like having lots of strings that connect blocks in special patterns. GraphRAG uses these strings to find the shortest, smartest path to answers, like a flashlight lighting the way in a dark room so you can see all the cool stuff inside! This helps you not just find any blocks, but the blocks that make the best patterns for what you’re trying to create or understand.\\n\\nNow, let’s imagine every block you have is part of a huge box of blocks that everyone in the world shares. Some kids know certain blocks very well, like they’re experts on them, because they’ve played with them a lot. If you’re building your castle and you’re unsure about how to use certain blocks, graphRAG can ask those expert kids. They can point out the best ways to use those blocks, so your castle doesn’t just stand, but becomes something really special.\\n\\nIn simpler words, graphRAG is like having a team of super smart, super creative friends who help you figure out the best answers to questions by connecting ideas, just like snapping together your favorite building blocks. It makes sure you have the pieces you need and that they fit together in the best way possible. It turns your questions into exciting adventures of building, exploring, and discovering new things, all while having the best building blocks and helpers by your side. So, with graphRAG, you’re never just guessing – you’re building something amazing out of all the little pieces of information you gather!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 577, 'prompt_tokens': 27, 'total_tokens': 604, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CHqdViQg2UbXfXC6PQgwBj38daoeV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--32e2bae3-c934-4fc1-b189-7b9d8a432f46-0', usage_metadata={'input_tokens': 27, 'output_tokens': 577, 'total_tokens': 604, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a second prompt \n",
        "\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"ml_concept\"],\n",
        "    template=\"Turn the concept description of {ml_concept} and explain it to me like I'm five in 500 words\",\n",
        ")\n",
        "chain_two = second_prompt | llm\n",
        "\n",
        "chain_two.invoke({\"ml_concept\": \"graphRAG\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkJKFyk1K-MO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alright, little buddy, let's talk about vector databases like we're diving into a fun story!\n",
            "\n",
            "Imagine you have a huge box of toys, and each toy is really special. Some are dolls, some are cars, and some are blocks. Now, let’s say each toy has a magical string of numbers tied to it. These numbers tell you all sorts of things about the toy—how colorful it is, how tall it is, how much fun it is, and more. These strings of numbers are called \"vectors\".\n",
            "\n",
            "Now, normally, when you want to find a toy, you might look through the box one by one until you find it. But what if that box is as big as a whole room? You'd be searching forever! That’s where vector databases come in. They are like a super-smart toy organizer that knows how to keep track of every single toy using those magical number strings.\n",
            "\n",
            "But these vector databases aren’t just for organizing toys. They help with some pretty cool stuff. Let’s talk about a few of them:\n",
            "\n",
            "1. **Finding Similar Toys**: Imagine you have a favorite teddy bear, and you want to find other toys that are just as cuddly. The vector database can look at the numbers tied to your teddy bear and quickly find other toys with similar numbers. So, you’ll get a list of cuddly toys in no time!\n",
            "\n",
            "2. **Making Recommendations**: Let’s say you’re playing with blocks today. The database notices and might suggest, “Hey, you like blocks, maybe you’d also like this cool puzzle.” It’s like when you’re watching a cartoon, and the TV suggests more shows you might love.\n",
            "\n",
            "3. **Grouping Toys Together**: Sometimes, it’s fun to arrange toys into groups, like all cars in one place and all stuffed animals in another. The vector database is brilliant at this too! It looks at the numbers and figures out which toys belong together based on their magical number strings.\n",
            "\n",
            "So, in this magical world, a vector database is like a clever friend who helps you find your toys more easily, suggests new fun toys to try, and helps you keep everything organized.\n",
            "\n",
            "And how do these numbers get made? Well, remember those magical strings of numbers we talked about? In real life, these often come from something called \"deep learning models.\" These are like super-smart robots that look at each toy (or data, in grown-up words) and figure out these magical number strings.\n",
            "\n",
            "In short, vector databases are magical not because they have sparkles but because they help us manage and find things easily using these number strings in a really smart way. They help people solve puzzles of finding, suggesting, and organizing all sorts of data—not just in toy boxes but in really important places like computers and the internet.\n",
            "\n",
            "And that’s the story of vector databases and their magic with numbers. Isn’t it cool to have a friend like that in the world of toys and technology?\n"
          ]
        }
      ],
      "source": [
        "# Chain the prompts and LLM sequentially\n",
        "overall_chain = prompt | llm | second_prompt | llm\n",
        "\n",
        "# Run the chain - THIS WILL NOT MENTION CHEEKY NANDOS as it is not passed to the second prompt\n",
        "response = overall_chain.invoke({\"concept\": \"vector databases\", \"ml_concept\": \"cheeky nandos\"})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alright, little buddy, let me explain what a \"cheeky Nando's\" is in a way that's easy and fun!\n",
            "\n",
            "Imagine you and your friends want to do something fun and tasty together. You know how sometimes you get really hungry and want something super yummy to eat? Well, there's a special place called Nando's where people love to go for a treat. It's like a fun food adventure!\n",
            "\n",
            "Nando's is a restaurant that is famous for serving delicious chicken. But it's not just any chicken; it's chicken that's been cooked with a lot of yummy spices called \"peri-peri\" sauce. This sauce is a bit spicy, kind of like how you might sprinkle a little pepper on your food, but with even more flavors! There are lots of different kinds of peri-peri sauce, from not-so-spicy to really spicy, so everyone can find the taste they like best.\n",
            "\n",
            "Now, when we say \"cheeky Nando's,\" it's a special way that people in the UK, which is a country across the ocean, talk about going to Nando's with their friends. It's called \"cheeky\" because it's a little bit sneaky and playful, like when you have a surprise ice cream after dinner and giggle because you didn't tell anyone! When people say they are having a \"cheeky Nando's,\" it means they're having a fun, casual time enjoying tasty chicken with friends, like going on a mini adventure.\n",
            "\n",
            "Just like when you decide to have an extra scoop of ice cream or go to the playground for a bit more fun, going to Nando's with your friends is a way to have a little extra happiness in the day. You don't always plan it for a special occasion; sometimes, it's just because you feel like having a little joy with your pals and eating delicious chicken.\n",
            "\n",
            "So, a \"cheeky Nando's\" is a fun, playful thing to do. It's not just about the food; it's also about being with friends, laughing, and having a good time together. It's like saying, \"Hey, let's have some fun and eat something yummy together!\"\n",
            "\n",
            "Now you know what a \"cheeky Nando's\" is all about! It's where friends go to enjoy tasty chicken and each other's company, like having a mini party with every bite. Sounds fun, right?\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# Create a function that takes the first LLM output and adds the ml_concept\n",
        "def add_ml_concept(llm_output):\n",
        "    return {\n",
        "        \"ml_concept\": \"cheeky nandos\"  # This will override whatever came from the first chain\n",
        "    }\n",
        "\n",
        "# Chain with the transformation function. This i think will just cause the second prompt to run with Cheeky Nandos as the ml concept but with no input from the first prompt.\n",
        "overall_chain = prompt | llm | RunnableLambda(add_ml_concept) | second_prompt | llm\n",
        "\n",
        "# Run the chain - only need to pass what the first prompt needs\n",
        "response = overall_chain.invoke({\"concept\": \"vector databases\"})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alright, imagine you're with your friends and you're all really hungry. You decide to go to a special place called Nando's. Nando's is a restaurant where they make delicious chicken, and it's really famous for a spicy sauce called Peri-Peri sauce. It's kind of like when you have those tasty sauces you put on your chicken nuggets, but this one is very special and a little bit spicy.\n",
            "\n",
            "Now, when people say they're going for a \"cheeky Nando's,\" it means they're going to Nando's in a fun and casual way, kind of like a little treat or surprise for themselves and their friends. The word \"cheeky\" is a funny way of saying it's a bit spontaneous or naughty, like you're doing something a bit sneaky but still nice.\n",
            "\n",
            "Imagine you're playing with your toys, and suddenly your mom says, \"Hey, let's stop for some ice cream!\" That's exciting and a bit unexpected, right? That's kind of like what a cheeky Nando's is for grown-ups and their friends. They might be doing something else, like shopping or watching a movie, and one of them might say, \"Let's have a cheeky Nando's!\" Then, they all go to enjoy some yummy chicken together.\n",
            "\n",
            "In Nando's, you get to choose how spicy you want your chicken to be. If you don't want it too spicy, you might pick the mild sauce, or if you're feeling adventurous, you might pick the extra hot sauce. It's like deciding if you want to play outside in the rain with a raincoat or without! Some people like the thrill of getting wet, while others like staying dry.\n",
            "\n",
            "So, a cheeky Nando’s is all about having fun, enjoying tasty food with your friends, and maybe doing something a little bit cheeky or unexpected. It's a special time where everyone is smiling and enjoying their favorite chicken, just like when you’re having a fun playdate with your best friends and sharing your favorite snacks.\n",
            "\n",
            "And there you have it! A cheeky Nando's is like having a super fun and tasty adventure with your buddies, where everyone gets to pick what they love to eat and laugh together. It's one of those happy times that make you feel warm and full, just like a bear hug. Even though it started as something grown-ups do, it's all about sharing good times and yummy food, which is something everyone can understand, no matter how old you are!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# Create a function that preserves the original input and adds it to the output\n",
        "def preserve_ml_concept(original_input):\n",
        "    def transform(llm_output):\n",
        "        return {\"ml_concept\": original_input.get(\"ml_concept\", \"\")}\n",
        "    return transform\n",
        "\n",
        "# You'll need to use RunnablePassthrough to capture the original input\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# More complex chain that preserves the ml_concept - Though i think the end result will still only considr cheeky nandos with no result to do with vector databases\n",
        "overall_chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        first_output=prompt | llm\n",
        "    ) | \n",
        "    RunnableLambda(lambda x: {\"ml_concept\": x.get(\"ml_concept\", \"\")}) |\n",
        "    second_prompt | \n",
        "    llm\n",
        ")\n",
        "\n",
        "response = overall_chain.invoke({\"concept\": \"vector databases\", \"ml_concept\": \"cheeky nandos\"})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final response:\n",
            "Imagine a world where plants have developed a cheeky reputation of their own, much like the universally loved concept of a \"cheeky Nandos.\" Just as a cheeky trip to Nandos involves a spur-of-the-moment, fun-filled outing with friends for some spicy chicken, plants could have their own version of a \"cheeky photosynthesis.\"\n",
            "\n",
            "In this playful scenario, picture a group of sun-loving plants deciding to engage in a cheeky photosynthesis session. Just like humans spontaneously decide to indulge in a cheeky Nandos, these plants opt for an unplanned, spirited round of energy-creating fun. They soak up sunlight with gusto, calling it their \"solar spice,\" and draw water and carbon dioxide to whip up their energy-rich glucose — their version of the warmth and satisfaction people get from a good meal.\n",
            "\n",
            "Perhaps, as they photosynthesize, these saucy plants imagine themselves hosting a mini fiesta, sending signals through their roots and leaves to nearby flora. \"Psst, feel like spicing up the day?\" they whisper to a neighboring fern, who eagerly joins the shindig. They exchange chlorophyll high-fives and bask in their radiant sun source, tossing around pollen like confetti.\n",
            "\n",
            "In this whimsical, imaginary world, plants aren't just silently standing in the garden. Instead, they're vibrant, cheeky life forms, embracing sunlight with the same excitement and camaraderie people reserve for their favorite cheeky Nandos adventure. It’s a botanical bash — with a side of photosynthetic spice.\n"
          ]
        }
      ],
      "source": [
        "# Define the new LLM for summarization\n",
        "llmSummariser = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# New summarizer prompt\n",
        "summarizer_prompt = PromptTemplate(\n",
        "    input_variables=[\"content\"],\n",
        "    template=\"Summarize the following content in 10 words or less: {content}\",\n",
        ")\n",
        "\n",
        "# New combo prompt that relates both concepts\n",
        "combo_prompt = PromptTemplate(\n",
        "    input_variables=[\"ml_concept\", \"summarised_content\"],\n",
        "    template=\"\"\"\n",
        "You are a creative AI assistant. Find an interesting connection or relationship between these two concepts:\n",
        "1. {ml_concept}\n",
        "2. {summarised_content}\n",
        "\n",
        "Explain how they might relate to each other in a fun and creative way.\n",
        "\"\"\",\n",
        ")\n",
        "\n",
        "# Function to prepare output for summarizer\n",
        "def prepare_for_summarizer(eli5_output):\n",
        "    return {\"content\": eli5_output.content}\n",
        "\n",
        "# Build the extended chain using your existing overall_chain\n",
        "extended_chain = (\n",
        "    overall_chain |\n",
        "    RunnableLambda(prepare_for_summarizer) |\n",
        "    summarizer_prompt |\n",
        "    llmSummariser |\n",
        "    RunnableLambda(lambda x: {\"ml_concept\": \"cheeky nandos\", \"summarised_content\": x.content}) |\n",
        "    combo_prompt |\n",
        "    llm\n",
        ")\n",
        "\n",
        "# Run the extended chain\n",
        "response = extended_chain.invoke({\"concept\": \"vector databases\"})\n",
        "print(\"Final response:\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ELI5 Output: Vector databases are specialized data storage systems designed to efficiently handle and retrieve high-dimensional vector data, often generated by embedding complex data like text, images, or audio into more manageable numerical forms. They enable similarity search and nearest neighbor queries, which are crucial for various machine learning and deep learning applications, such as recommendation systems and natural language processing tasks.\n",
            "\n",
            "Summary: Specialized databases for high-dimensional vector data, crucial for ML applications.\n",
            "\n",
            "Final response:\n",
            "Imagine a future where accessing a cheeky Nando's is not just about satisfying your cravings but also an experience finely tuned through the lenses of machine learning. Here's how these two seemingly unrelated concepts—cheeky Nando's and specialized databases for high-dimensional vector data—might creatively intertwine:\n",
            "\n",
            "Picture this: You walk into a cheeky Nando's powered by cutting-edge technology. Each customer interaction, from ordering to dining, has been optimized using machine learning models that thrive in environments of high-dimensional vector data. Every preference, from spicy to mild, drink of choice, or even your favorite seat by the window, is stored in a specialized database designed to handle complex and voluminous data.\n",
            "\n",
            "These databases function as the brains behind the scenes, analyzing and predicting crowd behaviors, optimizing kitchen workflows, and even personalizing your dining experience to a level never before imagined. It's as if the restaurant has a sixth sense, anticipating your next move, the perfect time to refill your drink, or suggesting the newest Peri-Peri twist flavor you're bound to love—before you even sit down.\n",
            "\n",
            "In this scenario, lunchtime at cheeky Nando's isn't just a meal. It's an orchestrated event where your tastes and tendencies are the muses for new culinary creations, all meticulously curated by advanced AI. The atmosphere is vibrant, the food arrives at the perfect moment, and every element of your cheeky Nando's experience is driven by the hidden, yet powerful, capabilities of high-dimensional vector data analytics.\n",
            "\n",
            "So, next time you're enjoying that cheeky Nando's, think of it as a culinary experience shaped not only by human hands but by the artful convergence of machine learning and big data magic—where a perfectly grilled chicken meets the future.\n"
          ]
        }
      ],
      "source": [
        "# Dictionary to store intermediate results\n",
        "debug_results = {}\n",
        "\n",
        "def store_result(key):\n",
        "    def _store(x):\n",
        "        debug_results[key] = x.content if hasattr(x, 'content') else x\n",
        "        return x\n",
        "    return _store\n",
        "\n",
        "# Chain with result storage\n",
        "extended_chain_stored = (\n",
        "    prompt |\n",
        "    llm |\n",
        "    RunnableLambda(store_result(\"eli5_output\")) |\n",
        "    RunnableLambda(prepare_for_summarizer) |\n",
        "    summarizer_prompt |\n",
        "    llmSummariser |\n",
        "    RunnableLambda(store_result(\"summary\")) |\n",
        "    RunnableLambda(lambda x: {\"ml_concept\": \"cheeky nandos\", \"summarised_content\": x.content}) |\n",
        "    combo_prompt |\n",
        "    llm\n",
        ")\n",
        "\n",
        "response = extended_chain_stored.invoke({\"concept\": \"vector databases\"})\n",
        "\n",
        "# Check the stored results\n",
        "print(\"ELI5 Output:\", debug_results.get(\"eli5_output\", \"Not found\"))\n",
        "print(\"\\nSummary:\", debug_results.get(\"summary\", \"Not found\"))\n",
        "print(\"\\nFinal response:\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mDDu1B_SLQls"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(metadata={}, page_content=\"Imagine a future where accessing a cheeky Nando's is not just about satisfying your cravings but\"), Document(metadata={}, page_content=\"also an experience finely tuned through the lenses of machine learning. Here's how these two\"), Document(metadata={}, page_content=\"seemingly unrelated concepts—cheeky Nando's and specialized databases for high-dimensional vector\"), Document(metadata={}, page_content='data—might creatively intertwine:'), Document(metadata={}, page_content=\"Picture this: You walk into a cheeky Nando's powered by cutting-edge technology. Each customer\"), Document(metadata={}, page_content='interaction, from ordering to dining, has been optimized using machine learning models that thrive'), Document(metadata={}, page_content='in environments of high-dimensional vector data. Every preference, from spicy to mild, drink of'), Document(metadata={}, page_content='choice, or even your favorite seat by the window, is stored in a specialized database designed to'), Document(metadata={}, page_content='handle complex and voluminous data.'), Document(metadata={}, page_content='These databases function as the brains behind the scenes, analyzing and predicting crowd behaviors,'), Document(metadata={}, page_content='optimizing kitchen workflows, and even personalizing your dining experience to a level never before'), Document(metadata={}, page_content=\"imagined. It's as if the restaurant has a sixth sense, anticipating your next move, the perfect\"), Document(metadata={}, page_content=\"time to refill your drink, or suggesting the newest Peri-Peri twist flavor you're bound to\"), Document(metadata={}, page_content='love—before you even sit down.'), Document(metadata={}, page_content=\"In this scenario, lunchtime at cheeky Nando's isn't just a meal. It's an orchestrated event where\"), Document(metadata={}, page_content='your tastes and tendencies are the muses for new culinary creations, all meticulously curated by'), Document(metadata={}, page_content='advanced AI. The atmosphere is vibrant, the food arrives at the perfect moment, and every element'), Document(metadata={}, page_content=\"of your cheeky Nando's experience is driven by the hidden, yet powerful, capabilities of\"), Document(metadata={}, page_content='high-dimensional vector data analytics.'), Document(metadata={}, page_content=\"So, next time you're enjoying that cheeky Nando's, think of it as a culinary experience shaped not\"), Document(metadata={}, page_content='only by human hands but by the artful convergence of machine learning and big data magic—where a'), Document(metadata={}, page_content='perfectly grilled chicken meets the future.')]\n"
          ]
        }
      ],
      "source": [
        "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
        "\n",
        "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 0,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([response.content])\n",
        "print(texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"Imagine a future where accessing a cheeky Nando's is not just about satisfying your cravings but also an experience finely tuned through the lenses of machine learning. Here's how these two seemingly unrelated concepts—cheeky Nando's and specialized databases for high-dimensional vector data—might creatively intertwine:\\n\\nPicture this: You walk into a cheeky Nando's powered by cutting-edge technology. Each customer interaction, from ordering to dining, has been optimized using machine learning models that thrive in environments of high\", \" using machine learning models that thrive in environments of high-dimensional vector data. Every preference, from spicy to mild, drink of choice, or even your favorite seat by the window, is stored in a specialized database designed to handle complex and voluminous data.\\n\\nThese databases function as the brains behind the scenes, analyzing and predicting crowd behaviors, optimizing kitchen workflows, and even personalizing your dining experience to a level never before imagined. It's as if the restaurant has a sixth sense, anticipating your next move,\", \" has a sixth sense, anticipating your next move, the perfect time to refill your drink, or suggesting the newest Peri-Peri twist flavor you're bound to love—before you even sit down.\\n\\nIn this scenario, lunchtime at cheeky Nando's isn't just a meal. It's an orchestrated event where your tastes and tendencies are the muses for new culinary creations, all meticulously curated by advanced AI. The atmosphere is vibrant, the food arrives at the perfect moment, and every\", \" the food arrives at the perfect moment, and every element of your cheeky Nando's experience is driven by the hidden, yet powerful, capabilities of high-dimensional vector data analytics.\\n\\nSo, next time you're enjoying that cheeky Nando's, think of it as a culinary experience shaped not only by human hands but by the artful convergence of machine learning and big data magic—where a perfectly grilled chicken meets the future.\"]\n"
          ]
        }
      ],
      "source": [
        "# When to Use TokenTextSplitter\n",
        "# Precise Control: When you need chunks that fit exactly within token windows\n",
        "# Cost Management: Token-based pricing means you want predictable token counts\n",
        "# Context Windows: When feeding chunks to LLMs, you need to respect their token limits\n",
        "# Embeddings: Many embedding models have specific token limits\n",
        "\n",
        "from langchain_text_splitters import TokenTextSplitter\n",
        "\n",
        "text_splitter = TokenTextSplitter(\n",
        "    chunk_size=100,        # 100 tokens per chunk\n",
        "    chunk_overlap=10,      # 10 token overlap between chunks\n",
        "    encoding_name=\"cl100k_base\"   # Tokenizer to use (gpt2, cl100k_base, etc.)\n",
        ")\n",
        "tokenSplitTexts = text_splitter.split_text(response.content)\n",
        "print(tokenSplitTexts)\n",
        "\n",
        "#Documents are Document objects rather than strings\n",
        "tokenSplitDocuments = text_splitter.create_documents([response.content])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6lfAdeuLhtp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Chunk\n",
            "\n",
            "Imagine a future where accessing a cheeky Nando's is not just about satisfying your cravings but also an experience finely tuned through the lenses of machine learning. Here's how these two seemingly unrelated concepts—cheeky Nando's and specialized databases for high-dimensional vector data—might creatively intertwine:\n",
            "\n",
            "Picture this: You walk into a cheeky Nando's powered by cutting-edge technology. Each customer interaction, from ordering to dining, has been optimized using machine learning models that thrive in environments of high\n",
            "\n",
            "Second Chunk\n",
            "\n",
            " using machine learning models that thrive in environments of high-dimensional vector data. Every preference, from spicy to mild, drink of choice, or even your favorite seat by the window, is stored in a specialized database designed to handle complex and voluminous data.\n",
            "\n",
            "These databases function as the brains behind the scenes, analyzing and predicting crowd behaviors, optimizing kitchen workflows, and even personalizing your dining experience to a level never before imagined. It's as if the restaurant has a sixth sense, anticipating your next move,\n",
            "\n",
            "Third Chunk\n",
            "\n",
            " has a sixth sense, anticipating your next move, the perfect time to refill your drink, or suggesting the newest Peri-Peri twist flavor you're bound to love—before you even sit down.\n",
            "\n",
            "In this scenario, lunchtime at cheeky Nando's isn't just a meal. It's an orchestrated event where your tastes and tendencies are the muses for new culinary creations, all meticulously curated by advanced AI. The atmosphere is vibrant, the food arrives at the perfect moment, and every\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Individual text chunks are just strings in the list\n",
        "print('First Chunk\\n')\n",
        "print(tokenSplitTexts[0] + '\\n')\n",
        "print('Second Chunk\\n')\n",
        "print(tokenSplitTexts[1] + '\\n')\n",
        "print('Third Chunk\\n')\n",
        "print(tokenSplitTexts[2] + '\\n')\n",
        "\n",
        "##Notice the chunk overlap here. Helps keep relations between chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Chunk\n",
            "\n",
            "Imagine a future where accessing a cheeky Nando's is not just about satisfying your cravings but also an experience finely tuned through the lenses of machine learning. Here's how these two seemingly unrelated concepts—cheeky Nando's and specialized databases for high-dimensional vector data—might creatively intertwine:\n",
            "\n",
            "Picture this: You walk into a cheeky Nando's powered by cutting-edge technology. Each customer interaction, from ordering to dining, has been optimized using machine learning models that thrive in environments of high\n",
            "\n",
            "Second Chunk\n",
            "\n",
            " using machine learning models that thrive in environments of high-dimensional vector data. Every preference, from spicy to mild, drink of choice, or even your favorite seat by the window, is stored in a specialized database designed to handle complex and voluminous data.\n",
            "\n",
            "These databases function as the brains behind the scenes, analyzing and predicting crowd behaviors, optimizing kitchen workflows, and even personalizing your dining experience to a level never before imagined. It's as if the restaurant has a sixth sense, anticipating your next move,\n",
            "\n",
            "Third Chunk\n",
            "\n",
            " has a sixth sense, anticipating your next move, the perfect time to refill your drink, or suggesting the newest Peri-Peri twist flavor you're bound to love—before you even sit down.\n",
            "\n",
            "In this scenario, lunchtime at cheeky Nando's isn't just a meal. It's an orchestrated event where your tastes and tendencies are the muses for new culinary creations, all meticulously curated by advanced AI. The atmosphere is vibrant, the food arrives at the perfect moment, and every\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Individual text chunks can be accessed with \"page_content\"\n",
        "print('First Chunk\\n')\n",
        "print(tokenSplitDocuments[0].page_content + '\\n')\n",
        "print('Second Chunk\\n')\n",
        "print(tokenSplitDocuments[1].page_content + '\\n')\n",
        "print('Third Chunk\\n')\n",
        "print(tokenSplitDocuments[2].page_content + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Z5sv4e3tLw2y"
      },
      "outputs": [],
      "source": [
        "# Import and instantiate OpenAI embeddings\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "#the embeddings model\n",
        "#embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=512) # These dimensions must ultimately match the dimensions expected by the vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "dqzoir4hMlfl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.024675864726305008, 0.012399776838719845, -0.03360205516219139, -0.018893426284193993, 0.04762009158730507, -0.002628381596878171, 0.0782536193728447, 0.05025877803564072, -0.07396575063467026, 0.03133443370461464, 0.0481148436665535, -0.06287501007318497, -0.06778132170438766, -0.04395066201686859, 0.019944777712225914, 0.008127368055284023, -0.05050615593791008, -0.022284552454948425, 0.01299760490655899, 0.027335168793797493, 0.07355345785617828, 0.07586231082677841, 0.01436848659068346, -0.02861328423023224, -0.015863055363297462, 0.03477709740400314, -0.028180373832583427, 0.08377837389707565, 0.02782992273569107, -0.0186975859105587, 0.006127736996859312, -0.04724902659654617, -0.032777465879917145, 0.03619951382279396, 0.0009489230578765273, 0.045270007103681564, 0.02494385652244091, 0.029128652065992355, 0.01337897777557373, 0.013976805843412876, -0.004189949482679367, -0.0006377690588124096, 0.07087353616952896, 0.05199041962623596, 0.08847854286432266, -0.0348595567047596, -0.06374083459377289, -0.02568598836660385, -0.05170181393623352, 0.05038246884942055, -0.09804379194974899, -0.02492324262857437, -0.09614723175764084, -0.018182216212153435, -0.012502850964665413, 0.026057053357362747, -0.030241848900914192, 0.03603459522128105, -0.011008280329406261, 0.07586231082677841, 0.003434933954849839, -0.04304361343383789, 0.07149197906255722, 0.02420172654092312, -0.0684409961104393, -0.06056615710258484, -0.021810414269566536, 0.04015754908323288, -0.022779308259487152, -0.003038099966943264, 0.01686287112534046, 0.04287869483232498, -0.05335099250078201, -0.003519969992339611, 0.08155198395252228, -0.1125565767288208, -0.015718752518296242, 0.05784501135349274, 0.007318239193409681, -0.06489525735378265, -0.04015754908323288, -0.0169762521982193, -0.013100679032504559, -0.028386522084474564, -0.033230990171432495, -0.09853854030370712, -0.059988945722579956, 0.006045277696102858, -0.07747025787830353, 0.08035632967948914, 0.014213875867426395, 0.05557738617062569, -0.05017632246017456, 0.03281869366765022, 0.0114824203774333, 0.1294606775045395, 0.016512421891093254, -0.03898250684142113, 0.02038799598813057, 0.002146511571481824, -0.0688120648264885, -0.023459594696760178, 0.0335814394056797, 0.01468801498413086, 0.07413066923618317, -0.07862468808889389, 0.01405926514416933, 0.03906496614217758, -0.0006316490471363068, 0.03665303811430931, -0.03149934858083725, -0.0401163175702095, -0.033107299357652664, 0.011533956974744797, 0.030942751094698906, -0.053474683314561844, 0.006112275645136833, -0.012327625416219234, 0.05702041834592819, -0.01103920303285122, -0.06341099739074707, -0.04234271124005318, 0.05607214197516441, -0.055907223373651505, -0.07083230465650558, -0.01626504398882389, -0.05763886123895645, -0.012286395765841007, -0.005880359560251236, -0.06563738733530045, 0.03477709740400314, -0.0007917355396784842, 0.0017419470241293311, -0.07928435504436493, -0.014172646217048168, 0.014801396057009697, -0.03151996433734894, 0.018378056585788727, -0.02842775173485279, 0.008354130201041698, -0.037931155413389206, -0.07301747053861618, -0.019182031974196434, -0.04745517298579216, -0.08526264131069183, -0.0005810784641653299, -0.05038246884942055, 0.06654443591833115, -0.0015499721048399806, 0.06460665166378021, -0.04807361587882042, 0.011008280329406261, -0.045270007103681564, -0.024078037589788437, 0.019944777712225914, 0.007864530198276043, 0.0034400876611471176, 0.051784273236989975, -0.029705865308642387, -0.05067107453942299, -0.07714042067527771, -0.043868206441402435, -0.002690225839614868, 0.030015086755156517, -0.010750596411526203, 0.011049509979784489, -0.0791606679558754, 0.011008280329406261, -0.07450173795223236, -0.04184795916080475, -0.07454296201467514, -0.03116951324045658, 0.011080432683229446, 0.034756481647491455, 0.06522509455680847, -0.017223630100488663, 0.060318782925605774, -0.1429014950990677, 0.04506386071443558, -0.051042139530181885, -0.061967961490154266, 0.03929172828793526, -0.0003240382357034832, -0.0013567087007686496, -0.017780229449272156, 0.0026593038346618414, -0.04642443358898163, -0.018944961950182915, -0.046012140810489655, 0.011606108397245407, -0.07771763950586319, 0.11626723408699036, 0.03207656368613243, 0.02995324321091175, 0.020686909556388855, -0.05504140257835388, 0.0272320955991745, -0.006230810657143593, 0.043868206441402435, 0.004646051209419966, 0.02554168552160263, 0.06831730902194977, 0.0163371954113245, -0.014389101415872574, 0.08035632967948914, 0.0015242036897689104, 0.009900237433612347, -0.011533956974744797, -0.028675127774477005, 0.009972388856112957, 0.038549598306417465, -0.0571853369474411, 0.03401435166597366, 0.017367932945489883, -0.0602775514125824, -0.052691321820020676, -0.053928207606077194, 0.058051157742738724, -0.006735872011631727, 0.05145443603396416, 0.027582546696066856, 0.009895083494484425, 0.0991157591342926, -0.003254554932937026, 0.012286395765841007, 0.0196046344935894, -0.03281869366765022, -0.10117723047733307, 0.09466296434402466, -0.01399742066860199, 0.017893610522150993, -0.04201287776231766, 0.013420207425951958, -0.016203200444579124, -0.0014778204495087266, 0.021872257813811302, -0.03455033525824547, -0.05949418991804123, 0.02098582312464714, 0.03541615232825279, -0.01536830235272646, -0.019109880551695824, 0.031437505036592484, 0.06040124222636223, 0.021707339212298393, 0.05557738617062569, -0.05706164985895157, 0.0006841522990725935, 0.02082090452313423, -0.049681566655635834, 0.03813730180263519, 0.07854222506284714, 0.013863424770534039, -0.0580923892557621, -0.018975883722305298, -0.07140952348709106, -0.08196427673101425, 0.013945884071290493, 0.0513719767332077, -0.019779860973358154, 0.027582546696066856, -0.023933734744787216, -0.05763886123895645, 0.08707673847675323, 0.016007360070943832, -0.005839130375534296, 0.02572721801698208, -0.018161602318286896, -0.06567861884832382, 0.013739735819399357, 0.009261179715394974, -0.01072998158633709, -0.011575186625123024, -0.04972279444336891, -0.08031509816646576, -0.03481832519173622, -0.0011628011707216501, -0.0415799655020237, 0.022552544251084328, 0.01482201088219881, -0.07384206354618073, -0.07124460488557816, 0.011296886950731277, -0.03731271252036095, -0.040982138365507126, -0.023521438241004944, 0.03756009042263031, -0.03819914534687996, -0.04362082853913307, -0.04444541782140732, 0.009895083494484425, -0.08179935812950134, -0.052402716130018234, -0.008080985397100449, 0.040672916918992996, 0.04378574714064598, 0.020882749930024147, 0.01367789227515459, 0.049516648054122925, 0.032962996512651443, 0.05487648397684097, -0.04428049921989441, 0.00810675323009491, 0.011296886950731277, -0.056937962770462036, 0.05722656846046448, -0.05994771420955658, 0.036117054522037506, 0.035684145987033844, -0.00420798733830452, -0.014791089110076427, 0.021666111424565315, 0.07429558783769608, -0.046341974288225174, -0.09350854158401489, 0.002692802809178829, 0.09326116740703583, -0.031396277248859406, 0.005215533543378115, -0.07986157387495041, -0.044033121317625046, 0.01726485975086689, 0.0016981406370177865, -0.045847222208976746, -0.01637842506170273, 0.010760903358459473, 0.04201287776231766, 0.01186379324644804, 0.052402716130018234, -0.035828448832035065, 0.03753947466611862, -0.062297798693180084, 0.01156487874686718, 0.013327441178262234, -0.037621933966875076, -0.032942384481430054, -0.01551260519772768, 0.02058383636176586, -0.01292545348405838, 0.02145996317267418, -0.005339222494512796, -0.03168488293886185, -0.03788992390036583, -0.009364253841340542, 0.03312791511416435, -0.04423927143216133, -0.034612178802490234, 0.042837467044591904, 0.05780377984046936, 0.07722288370132446, -0.011750412173569202, -0.026551807299256325, 0.06101968139410019, -0.04263132065534592, -0.03663242608308792, 0.043249763548374176, 0.02236701175570488, 0.010678444989025593, -0.03391127660870552, -0.07066739350557327, -0.03044799715280533, 0.0353955402970314, 0.08258271962404251, 0.05945296213030815, 0.02002723701298237, -0.010023926384747028, -0.06765763461589813, -0.04032246768474579, -0.004725933074951172, -0.06369960308074951, -0.028675127774477005, -0.025150004774332047, -0.03391127660870552, -0.01223485916852951, -0.0689769834280014, -0.03086029179394245, 0.06930681318044662, 0.02479955367743969, 0.04547615721821785, 0.007967604324221611, -0.031107669696211815, 0.005906128324568272, 0.03772500529885292, -0.09416821599006653, -0.026881644502282143, 0.06621459871530533, 0.011430882848799229, -0.13572756946086884, -0.11956559866666794, 0.0015577026642858982, -0.011152584105730057, -0.11577247828245163, 0.00756561616435647, 0.04104398190975189, -0.0410233698785305, 0.03298361226916313, 0.008632429875433445, -0.012090555392205715, 0.053639598190784454, 0.03028307855129242, -0.014852932654321194, -0.03529246523976326, -0.006550339516252279, -0.03984832763671875, 0.021418733522295952, 0.0012040307046845555, 0.0328599251806736, 0.030777834355831146, -0.06341099739074707, -0.010317686013877392, 0.0025807099882513285, 0.01056506298482418, 0.04110582545399666, 0.03417927026748657, 0.0003736424841918051, -0.025912750512361526, -0.006942019797861576, 0.026675496250391006, 0.0010681021958589554, 0.07561492919921875, 0.045393697917461395, -0.02737639844417572, 0.06646198034286499, 0.012513157911598682, 0.007766610011458397, 0.08192304521799088, 0.01599705219268799, -0.004568745847791433, 0.014698321931064129, -0.05640197917819023, -0.005040308460593224, -0.003396281274035573, -0.022140249609947205, 0.030777834355831146, -0.010688751935958862, 0.023315291851758957, 0.028530824929475784, 0.003445241367444396, 0.0927664116024971, -0.08649952709674835, 0.015564141795039177, 0.04514632001519203, -0.006880175322294235, 0.03586968034505844, -0.03743639960885048, 0.0301387757062912, -0.13193444907665253, 0.06477157026529312, -0.04019877687096596, -0.06992525607347488, -0.007179089356213808, -0.0025446342770010233, -0.003661696333438158, 0.01850174553692341, 0.003179826308041811, -0.025150004774332047, 0.047826237976551056, -0.039003122597932816, 0.042074721306562424, 0.023335905745625496, 0.0037158101331442595, 0.024098651483654976, -0.011399961076676846, 0.00992085225880146, 0.0344884917140007, -0.011472112499177456, -0.05458787828683853, 0.013904654420912266, 0.05091845244169235, -0.048898205161094666, 0.007606845814734697, -0.008725196123123169, 0.026077669113874435, 0.023789430037140846, 0.013141907751560211, -0.029128652065992355, 0.022119635716080666, 0.00935909990221262, -0.0393948033452034, 0.04271377995610237, -0.018202831968665123, 0.024242954328656197, -0.032612547278404236, 0.003339590737596154, -0.027891768142580986, -0.03617890179157257, 0.028056684881448746, -0.0034400876611471176, 0.025892136618494987, -0.06992525607347488, -0.006071045994758606, -0.02234639786183834, 0.10241411626338959, -0.02401619218289852, 0.003543161554262042, -0.030200621113181114, -0.006581261288374662, -0.0800677165389061, -0.010080616921186447, 0.024263570085167885, 0.009271487593650818, 0.01261623203754425, -0.023500824347138405, 0.0847678855061531, 0.008957112208008766, 0.0039786482229828835, -0.039147425442934036, -0.004723356571048498, -0.004478556104004383, 0.022470086812973022, 0.012595617212355137, 0.051949188113212585]\n"
          ]
        }
      ],
      "source": [
        "# Turn the first text chunk into a vector with the embedding\n",
        "\n",
        "query_result = embeddings.embed_query(tokenSplitTexts[0])\n",
        "print(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "QaOY5bIZM3Xz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pinecone import Pinecone\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "# Initialize the Pinecone client first - this is the actual pinecone client instance\n",
        "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
        "\n",
        "# Then create or connect to an index\n",
        "index_name = \"langchain-test-index\"  # You need to specify this\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Finally, create the vector store - this is the langchain wrapper\n",
        "vectorstore = PineconeVectorStore(\n",
        "    index=index, # this index is the link to the Pinecone Client itself\n",
        "    embedding=embeddings,  # Your OpenAI embeddings object\n",
        "    text_key=\"text\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Delete all vectors from the current index\n",
        "index.delete(delete_all=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "lZhSUt3FNBzN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x000001D34F580CB0>\n"
          ]
        }
      ],
      "source": [
        "# Upload vectors to Pinecone (the documents are converted to vectors of X dimensions by this call)\n",
        "search = vectorstore.from_documents(tokenSplitDocuments, embeddings, index_name=index_name) # search is of same type as vectorstore <langchain_pinecone.vectorstores.PineconeVectorStore object>\n",
        "\n",
        "print(search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCXVuXwPNKcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id='05b30e0d-bfbd-4718-8b83-a84ae2ff05b0', metadata={}, page_content=\"Imagine a future where accessing a cheeky Nando's is not just about satisfying your cravings but also an experience finely tuned through the lenses of machine learning. Here's how these two seemingly unrelated concepts—cheeky Nando's and specialized databases for high-dimensional vector data—might creatively intertwine:\\n\\nPicture this: You walk into a cheeky Nando's powered by cutting-edge technology. Each customer interaction, from ordering to dining, has been optimized using machine learning models that thrive in environments of high\"), Document(id='9605a6ad-d0fb-48cd-88ae-a9bc12fd533d', metadata={}, page_content=\" using machine learning models that thrive in environments of high-dimensional vector data. Every preference, from spicy to mild, drink of choice, or even your favorite seat by the window, is stored in a specialized database designed to handle complex and voluminous data.\\n\\nThese databases function as the brains behind the scenes, analyzing and predicting crowd behaviors, optimizing kitchen workflows, and even personalizing your dining experience to a level never before imagined. It's as if the restaurant has a sixth sense, anticipating your next move,\"), Document(id='d37c4b41-87ce-48b1-aad7-d002b9bba8df', metadata={}, page_content=\" has a sixth sense, anticipating your next move, the perfect time to refill your drink, or suggesting the newest Peri-Peri twist flavor you're bound to love—before you even sit down.\\n\\nIn this scenario, lunchtime at cheeky Nando's isn't just a meal. It's an orchestrated event where your tastes and tendencies are the muses for new culinary creations, all meticulously curated by advanced AI. The atmosphere is vibrant, the food arrives at the perfect moment, and every\"), Document(id='bf4b73bd-f21a-4a2f-be43-f9c50e0ae17b', metadata={}, page_content=\" the food arrives at the perfect moment, and every element of your cheeky Nando's experience is driven by the hidden, yet powerful, capabilities of high-dimensional vector data analytics.\\n\\nSo, next time you're enjoying that cheeky Nando's, think of it as a culinary experience shaped not only by human hands but by the artful convergence of machine learning and big data magic—where a perfectly grilled chicken meets the future.\")]\n"
          ]
        }
      ],
      "source": [
        "# Do a simple vector similarity search\n",
        "\n",
        "query = \"How does cheeky nandos related to ML?\"\n",
        "result = search.similarity_search(query, k=2)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score: 0.6796\n",
            "Content: Imagine a future where accessing a cheeky Nando's is not just about satisfying your cravings but als...\n",
            "\n",
            "Score: 0.3688\n",
            "Content:  using machine learning models that thrive in environments of high-dimensional vector data. Every pr...\n",
            "\n",
            "Score: 0.5985\n",
            "Content:  has a sixth sense, anticipating your next move, the perfect time to refill your drink, or suggestin...\n",
            "\n",
            "Score: 0.6199\n",
            "Content:  the food arrives at the perfect moment, and every element of your cheeky Nando's experience is driv...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Or get similarity scores\n",
        "result_with_scores = search.similarity_search_with_score(query)\n",
        "for doc, score in result_with_scores:\n",
        "    print(f\"Score: {score:.4f}\")\n",
        "    print(f\"Content: {doc.page_content[:100]}...\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "4Ogz8luZNRnJ"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.tools import PythonREPLTool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain import hub\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Create the Python tool\n",
        "python_tool = PythonREPLTool()\n",
        "\n",
        "# Get a prompt template\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "# Create the agent\n",
        "agent = create_react_agent(llm, [python_tool], prompt)\n",
        "\n",
        "# Create the agent executor\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, \n",
        "    tools=[python_tool], \n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "BVHMDj0sNi09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mWe can use the quadratic formula to find the roots of the quadratic function.\n",
            "Action: Python_REPL\n",
            "Action Input: import cmath\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mNow that we have imported the cmath module, we can use it to calculate the roots of the quadratic function.\n",
            "Action: Python_REPL\n",
            "Action Input: a = 3, b = 2, c = -1\u001b[0m\u001b[36;1m\u001b[1;3mSyntaxError(\"invalid syntax. Maybe you meant '==' or ':=' instead of '='?\", ('<string>', 1, 1, 'a = 3, b = 2, c = -1\\n', 1, 6))\u001b[0m\u001b[32;1m\u001b[1;3mI need to assign values to variables a, b, and c separately.\n",
            "Action: Python_REPL\n",
            "Action Input: a = 3\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mNow I need to assign values to variables b and c.\n",
            "Action: Python_REPL\n",
            "Action Input: b = 2\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mNow I need to assign a value to variable c.\n",
            "Action: Python_REPL\n",
            "Action Input: c = -1\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mNow that I have assigned values to variables a, b, and c, I can calculate the roots of the quadratic function.\n",
            "Action: Python_REPL\n",
            "Action Input: root1 = (-b + cmath.sqrt(b**2 - 4*a*c)) / (2*a)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mI need to calculate the second root using the quadratic formula.\n",
            "Action: Python_REPL\n",
            "Action Input: root2 = (-b - cmath.sqrt(b**2 - 4*a*c)) / (2*a)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The roots of the quadratic function 3 * x**2 + 2*x -1 are x = 0.3333333333333333 and x = -1.0\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Find the roots (zeros) if the quadratic function 3 * x**2 + 2*x -1',\n",
              " 'output': 'The roots of the quadratic function 3 * x**2 + 2*x -1 are x = 0.3333333333333333 and x = -1.0'}"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Execute the Python agent\n",
        "\n",
        "agent_executor.invoke({\"input\": \"Find the roots (zeros) if the quadratic function 3 * x**2 + 2*x -1\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "#An agent with enhanced capabilities including file access, more comparable to Claude Code:\n",
        "from langchain_experimental.tools import PythonREPLTool\n",
        "from langchain_community.tools.shell.tool import ShellTool\n",
        "from langchain_community.agent_toolkits import FileManagementToolkit\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain import hub\n",
        "\n",
        "# File-focused tools\n",
        "file_toolkit = FileManagementToolkit(\n",
        "    root_dir=\"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\"  # Restrict to specific directory\n",
        ")\n",
        "\n",
        "tools = [\n",
        "    PythonREPLTool(),\n",
        "    ShellTool(),  # For running terminal commands\n",
        "    *file_toolkit.get_tools()  # File read/write/search tools\n",
        "]\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
        "prompt = hub.pull(\"hwchase17/react\") # from langchain hub\n",
        "\n",
        "agent2 = create_react_agent(llm, tools, prompt)\n",
        "agent_executor_super = AgentExecutor(\n",
        "    agent=agent2, \n",
        "    tools=tools, \n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to calculate the roots of the quadratic equation first. The formula to find the roots of a quadratic equation is (-b ± sqrt(b^2 - 4ac)) / (2a). Here, a = 3, b = 2, and c = -1.\n",
            "Action: Python_REPL\n",
            "Action Input: \n",
            "```python\n",
            "import math\n",
            "\n",
            "a = 3\n",
            "b = 2\n",
            "c = -1\n",
            "\n",
            "# calculate the discriminant\n",
            "D = b**2 - 4*a*c\n",
            "\n",
            "# calculate two solutions\n",
            "sol1 = (-b - math.sqrt(D)) / (2*a)\n",
            "sol2 = (-b + math.sqrt(D)) / (2*a)\n",
            "\n",
            "sol1, sol2\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThe roots of the equation are -0.3333333333333333 and 1.0. Now I need to write these results to a file.\n",
            "Action: write_file\n",
            "Action Input: \n",
            "```json\n",
            "{\n",
            "  \"file_path\": \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\quadratic_results.txt\",\n",
            "  \"text\": \"The roots of the equation 3x^2 + 2x - 1 are -0.3333333333333333 and 1.0.\"\n",
            "}\n",
            "```\u001b[0m"
          ]
        },
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for WriteFileInput\ntext\n  Field required [type=missing, input_value={'file_path': '```json\\n{...3333 and 1.0.\"\\n}\\n```'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent_executor_super\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[33;43mFind the roots of 3x^2 + 2x - 1. Then write the results to a file using these exact steps:\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[33;43m    1. Calculate the roots using Python\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[33;43m    2. Use write_file tool with these EXACT parameters:\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[33;43m       - file_path: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mpeter\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mDocuments\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mAgentPlaygroundTest\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mquadratic_results.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[33;43m       - text: the explanation text (as a literal string, not a variable)\u001b[39;49m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[33;43m    Do NOT use Python variables inside the write_file JSON. Write the actual calculated values directly.\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1334\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1408\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1406\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[32m   1407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[32m-> \u001b[39m\u001b[32m1408\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1413\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1433\u001b[39m, in \u001b[36mAgentExecutor._perform_agent_action\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[39m\n\u001b[32m   1431\u001b[39m         tool_run_kwargs[\u001b[33m\"\u001b[39m\u001b[33mllm_prefix\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1432\u001b[39m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     observation = \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1441\u001b[39m     tool_run_kwargs = \u001b[38;5;28mself\u001b[39m._action_agent.tool_run_logging_kwargs()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:892\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    891\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    893\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    894\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:854\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    852\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    858\u001b[39m         tool_kwargs |= {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:769\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    762\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    763\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    766\u001b[39m ):\n\u001b[32m    767\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    768\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:650\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    648\u001b[39m key_ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(get_fields(input_args).keys()))\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModel):\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m     \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n\u001b[32m    652\u001b[39m     input_args.parse_obj({key_: tool_input})\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\pydantic\\main.py:705\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    701\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    702\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    703\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mValidationError\u001b[39m: 1 validation error for WriteFileInput\ntext\n  Field required [type=missing, input_value={'file_path': '```json\\n{...3333 and 1.0.\"\\n}\\n```'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"
          ]
        }
      ],
      "source": [
        "agent_executor_super.invoke({\n",
        "    \"input\": \"\"\"Find the roots of 3x^2 + 2x - 1. Then write the results to a file using these exact steps:\n",
        "    1. Calculate the roots using Python\n",
        "    2. Use write_file tool with these EXACT parameters:\n",
        "       - file_path: \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\quadratic_results.txt\"\n",
        "       - text: the explanation text (as a literal string, not a variable)\n",
        "    \n",
        "    Do NOT use Python variables inside the write_file JSON. Write the actual calculated values directly.\"\"\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFirst, I need to calculate the roots of the quadratic equation. The roots of a quadratic equation ax^2 + bx + c = 0 can be calculated using the formula: x = [-b ± sqrt(b^2 - 4ac)] / (2a). In this case, a = 3, b = 2, and c = -1.\n",
            "Action: Python_REPL\n",
            "Action Input: \n",
            "```python\n",
            "import math\n",
            "\n",
            "a = 3\n",
            "b = 2\n",
            "c = -1\n",
            "\n",
            "# calculate the discriminant\n",
            "D = b**2 - 4*a*c\n",
            "\n",
            "# calculate the two solutions\n",
            "x1 = (-b - math.sqrt(D)) / (2*a)\n",
            "x2 = (-b + math.sqrt(D)) / (2*a)\n",
            "\n",
            "x1, x2\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThe roots of the equation are calculated. Now I need to write these results to a file.\n",
            "Action: write_file\n",
            "Action Input: {\"file_path\": \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\quadratic_results.txt\", \"text\": \"The roots of the equation 3x^2 + 2x - 1 are x1 = -1.0 and x2 = 0.3333333333333333.\"}\u001b[0m"
          ]
        },
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for WriteFileInput\ntext\n  Field required [type=missing, input_value={'file_path': '{\"file_pat... 0.3333333333333333.\"}'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent_executor_super\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[33;43mCalculate the roots of 3x^2 + 2x - 1. Then use the write_file tool with this EXACT format (no code blocks, no quotes around the JSON):\u001b[39;49m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[33;43mAction: write_file\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[33;43mAction Input: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mpeter\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mDocuments\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mAgentPlaygroundTest\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mquadratic_results.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYour calculated explanation here\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m}\u001b[39;49m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[33;43mDo NOT wrap the Action Input in ```json``` code blocks. Just use plain JSON.\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1334\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1408\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1406\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[32m   1407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[32m-> \u001b[39m\u001b[32m1408\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1413\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1433\u001b[39m, in \u001b[36mAgentExecutor._perform_agent_action\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[39m\n\u001b[32m   1431\u001b[39m         tool_run_kwargs[\u001b[33m\"\u001b[39m\u001b[33mllm_prefix\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1432\u001b[39m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     observation = \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1441\u001b[39m     tool_run_kwargs = \u001b[38;5;28mself\u001b[39m._action_agent.tool_run_logging_kwargs()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:892\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    891\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    893\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    894\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:854\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    852\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    858\u001b[39m         tool_kwargs |= {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:769\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    762\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    763\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    766\u001b[39m ):\n\u001b[32m    767\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    768\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:650\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    648\u001b[39m key_ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(get_fields(input_args).keys()))\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModel):\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m     \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n\u001b[32m    652\u001b[39m     input_args.parse_obj({key_: tool_input})\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\pydantic\\main.py:705\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    701\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    702\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    703\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mValidationError\u001b[39m: 1 validation error for WriteFileInput\ntext\n  Field required [type=missing, input_value={'file_path': '{\"file_pat... 0.3333333333333333.\"}'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"
          ]
        }
      ],
      "source": [
        "agent_executor_super.invoke({\n",
        "    \"input\": \"\"\"Calculate the roots of 3x^2 + 2x - 1. Then use the write_file tool with this EXACT format (no code blocks, no quotes around the JSON):\n",
        "\n",
        "Action: write_file\n",
        "Action Input: {\"file_path\": \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\quadratic_results.txt\", \"text\": \"Your calculated explanation here\"}\n",
        "\n",
        "Do NOT wrap the Action Input in ```json``` code blocks. Just use plain JSON.\"\"\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool Name: copy_file\n",
            "Tool Description: Create a copy of a file in a specified location\n",
            "Expected Parameters: dict_keys(['source_path', 'destination_path'])\n",
            "  - source_path: <class 'str'>\n",
            "  - destination_path: <class 'str'>\n",
            "---\n",
            "Tool Name: file_delete\n",
            "Tool Description: Delete a file\n",
            "Expected Parameters: dict_keys(['file_path'])\n",
            "  - file_path: <class 'str'>\n",
            "---\n",
            "Tool Name: file_search\n",
            "Tool Description: Recursively search for files in a subdirectory that match the regex pattern\n",
            "Expected Parameters: dict_keys(['dir_path', 'pattern'])\n",
            "  - dir_path: <class 'str'>\n",
            "  - pattern: <class 'str'>\n",
            "---\n",
            "Tool Name: move_file\n",
            "Tool Description: Move or rename a file from one location to another\n",
            "Expected Parameters: dict_keys(['source_path', 'destination_path'])\n",
            "  - source_path: <class 'str'>\n",
            "  - destination_path: <class 'str'>\n",
            "---\n",
            "Tool Name: read_file\n",
            "Tool Description: Read file from disk\n",
            "Expected Parameters: dict_keys(['file_path'])\n",
            "  - file_path: <class 'str'>\n",
            "---\n",
            "Tool Name: write_file\n",
            "Tool Description: Write file to disk\n",
            "Expected Parameters: dict_keys(['file_path', 'text', 'append'])\n",
            "  - file_path: <class 'str'>\n",
            "  - text: <class 'str'>\n",
            "  - append: <class 'bool'>\n",
            "---\n",
            "Tool Name: list_directory\n",
            "Tool Description: List files and directories in a specified folder\n",
            "Expected Parameters: dict_keys(['dir_path'])\n",
            "  - dir_path: <class 'str'>\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Check all available tools and their expected inputs\n",
        "for tool in file_toolkit.get_tools():\n",
        "    print(f\"Tool Name: {tool.name}\")\n",
        "    print(f\"Tool Description: {tool.description}\")\n",
        "    if hasattr(tool, 'args_schema') and tool.args_schema:\n",
        "        print(f\"Expected Parameters: {tool.args_schema.model_fields.keys()}\")\n",
        "        for field_name, field_info in tool.args_schema.model_fields.items():\n",
        "            print(f\"  - {field_name}: {field_info.annotation}\")\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File written successfully to C:\\Users\\peter\\Documents\\AgentPlaygroundTest\\test.txt.\n"
          ]
        }
      ],
      "source": [
        "# Test the write_file tool directly\n",
        "write_tool = None\n",
        "for tool in file_toolkit.get_tools():\n",
        "    if tool.name == \"write_file\":\n",
        "        write_tool = tool\n",
        "        break\n",
        "\n",
        "if write_tool:\n",
        "    result = write_tool.run({\n",
        "        \"file_path\": \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\test.txt\",\n",
        "        \"text\": \"Test content\"\n",
        "    })\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add this before creating the agent to see raw LLM output\n",
        "import logging\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "logger = logging.getLogger(\"langchain.agents.agent\")\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "\n",
        "\n",
        "custom_prompt = PromptTemplate.from_template(\"\"\"\n",
        "You are an assistant with access to tools. When using the write_file tool, you MUST use this exact format:\n",
        "\n",
        "Action: write_file\n",
        "Action Input: {{\"file_path\": \"full/path/to/file\", \"text\": \"content to write\"}}\n",
        "\n",
        "Never use code blocks, never use variables in the JSON, always use literal string values.\n",
        "\n",
        "Tools available: {tools}\n",
        "Tool names: {tool_names}\n",
        "\n",
        "Question: {input}\n",
        "Thought: I should think about what needs to be done\n",
        "{agent_scratchpad}\n",
        "\"\"\")\n",
        "\n",
        "agent3 = create_react_agent(llm, tools, custom_prompt)\n",
        "agent_executor_custom = AgentExecutor(\n",
        "    agent=agent3, \n",
        "    tools=tools, \n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a6dd1b51-a596-4abd-a4df-3eab1af62688', 'json_data': {'messages': [{'content': '\\nYou are an assistant with access to tools. When using the write_file tool, you MUST use this exact format:\\n\\nAction: write_file\\nAction Input: {\"file_path\": \"full/path/to/file\", \"text\": \"content to write\"}\\n\\nNever use code blocks, never use variables in the JSON, always use literal string values.\\n\\nTools available: Python_REPL - A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\nterminal - Run shell commands on this Windows machine.\\ncopy_file - Create a copy of a file in a specified location\\nfile_delete - Delete a file\\nfile_search - Recursively search for files in a subdirectory that match the regex pattern\\nmove_file - Move or rename a file from one location to another\\nread_file - Read file from disk\\nwrite_file - Write file to disk\\nlist_directory - List files and directories in a specified folder\\nTool names: Python_REPL, terminal, copy_file, file_delete, file_search, move_file, read_file, write_file, list_directory\\n\\nQuestion: Calculate the roots of 3x^2 + 2x - 1. Then use the write_file tool with this EXACT format (no code blocks, no quotes around the JSON):\\n\\nAction: write_file\\nAction Input: {\"file_path\": \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\quadratic_results.txt\", \"text\": \"Your calculated explanation here\"}\\n\\nDo NOT wrap the Action Input in ```json``` code blocks. Just use plain JSON. Ensure that the json key and value are wrapped in double quotes not single quotes\\nThought: I should think about what needs to be done\\n\\n', 'role': 'user'}], 'model': 'gpt-4', 'stop': ['\\nObservation'], 'stream': True, 'temperature': 0.0}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D357D39B30>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D330FB1F40> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D357E3DA90>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Sep 2025 17:31:43 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'ipv-p3uuox'), (b'openai-processing-ms', b'355'), (b'openai-project', b'proj_voBSgQh5Xdl46y0VcbQ4BGbR'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'374'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'3325'), (b'x-ratelimit-reset-requests', b'1m16.115s'), (b'x-ratelimit-reset-tokens', b'40.048s'), (b'x-request-id', b'req_351cafc437de4c38bdb7fa182039f454'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98230edbbeeff837-MAN'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sat, 20 Sep 2025 17:31:43 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'ipv-p3uuox', 'openai-processing-ms': '355', 'openai-project': 'proj_voBSgQh5Xdl46y0VcbQ4BGbR', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '374', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '3325', 'x-ratelimit-reset-requests': '1m16.115s', 'x-ratelimit-reset-tokens': '40.048s', 'x-request-id': 'req_351cafc437de4c38bdb7fa182039f454', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '98230edbbeeff837-MAN', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
            "DEBUG:openai._base_client:request_id: req_351cafc437de4c38bdb7fa182039f454\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2b2c494c-3aa5-4fa8-b928-8065e64c5382', 'json_data': {'messages': [{'content': '\\nYou are an assistant with access to tools. When using the write_file tool, you MUST use this exact format:\\n\\nAction: write_file\\nAction Input: {\"file_path\": \"full/path/to/file\", \"text\": \"content to write\"}\\n\\nNever use code blocks, never use variables in the JSON, always use literal string values.\\n\\nTools available: Python_REPL - A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\nterminal - Run shell commands on this Windows machine.\\ncopy_file - Create a copy of a file in a specified location\\nfile_delete - Delete a file\\nfile_search - Recursively search for files in a subdirectory that match the regex pattern\\nmove_file - Move or rename a file from one location to another\\nread_file - Read file from disk\\nwrite_file - Write file to disk\\nlist_directory - List files and directories in a specified folder\\nTool names: Python_REPL, terminal, copy_file, file_delete, file_search, move_file, read_file, write_file, list_directory\\n\\nQuestion: Calculate the roots of 3x^2 + 2x - 1. Then use the write_file tool with this EXACT format (no code blocks, no quotes around the JSON):\\n\\nAction: write_file\\nAction Input: {\"file_path\": \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\quadratic_results.txt\", \"text\": \"Your calculated explanation here\"}\\n\\nDo NOT wrap the Action Input in ```json``` code blocks. Just use plain JSON. Ensure that the json key and value are wrapped in double quotes not single quotes\\nThought: I should think about what needs to be done\\nFirst, we need to calculate the roots of the quadratic equation 3x^2 + 2x - 1 = 0. The roots of a quadratic equation ax^2 + bx + c = 0 can be calculated using the formula:\\n\\nx = [-b ± sqrt(b^2 - 4ac)] / 2a\\n\\nLet\\'s calculate the roots using the Python_REPL tool.\\nObservation: Invalid Format: Missing \\'Action:\\' after \\'Thought:\\'\\nThought: \\n', 'role': 'user'}], 'model': 'gpt-4', 'stop': ['\\nObservation'], 'stream': True, 'temperature': 0.0}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mFirst, we need to calculate the roots of the quadratic equation 3x^2 + 2x - 1 = 0. The roots of a quadratic equation ax^2 + bx + c = 0 can be calculated using the formula:\n",
            "\n",
            "x = [-b ± sqrt(b^2 - 4ac)] / 2a\n",
            "\n",
            "Let's calculate the roots using the Python_REPL tool.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Sep 2025 17:31:46 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'ipv-p3uuox'), (b'openai-processing-ms', b'368'), (b'openai-project', b'proj_voBSgQh5Xdl46y0VcbQ4BGbR'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'393'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'3245'), (b'x-ratelimit-reset-requests', b'1m22.181s'), (b'x-ratelimit-reset-tokens', b'40.526s'), (b'x-request-id', b'req_6fa6d5d7e7f7439c88ec8087cff5cd8d'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98230eebce9ff837-MAN'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sat, 20 Sep 2025 17:31:46 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'ipv-p3uuox', 'openai-processing-ms': '368', 'openai-project': 'proj_voBSgQh5Xdl46y0VcbQ4BGbR', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '393', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9990', 'x-ratelimit-remaining-tokens': '3245', 'x-ratelimit-reset-requests': '1m22.181s', 'x-ratelimit-reset-tokens': '40.526s', 'x-request-id': 'req_6fa6d5d7e7f7439c88ec8087cff5cd8d', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '98230eebce9ff837-MAN', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
            "DEBUG:openai._base_client:request_id: req_6fa6d5d7e7f7439c88ec8087cff5cd8d\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-106ace2b-b2dc-4bf9-b46f-985f318fc969', 'json_data': {'messages': [{'content': '\\nYou are an assistant with access to tools. When using the write_file tool, you MUST use this exact format:\\n\\nAction: write_file\\nAction Input: {\"file_path\": \"full/path/to/file\", \"text\": \"content to write\"}\\n\\nNever use code blocks, never use variables in the JSON, always use literal string values.\\n\\nTools available: Python_REPL - A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\nterminal - Run shell commands on this Windows machine.\\ncopy_file - Create a copy of a file in a specified location\\nfile_delete - Delete a file\\nfile_search - Recursively search for files in a subdirectory that match the regex pattern\\nmove_file - Move or rename a file from one location to another\\nread_file - Read file from disk\\nwrite_file - Write file to disk\\nlist_directory - List files and directories in a specified folder\\nTool names: Python_REPL, terminal, copy_file, file_delete, file_search, move_file, read_file, write_file, list_directory\\n\\nQuestion: Calculate the roots of 3x^2 + 2x - 1. Then use the write_file tool with this EXACT format (no code blocks, no quotes around the JSON):\\n\\nAction: write_file\\nAction Input: {\"file_path\": \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\quadratic_results.txt\", \"text\": \"Your calculated explanation here\"}\\n\\nDo NOT wrap the Action Input in ```json``` code blocks. Just use plain JSON. Ensure that the json key and value are wrapped in double quotes not single quotes\\nThought: I should think about what needs to be done\\nFirst, we need to calculate the roots of the quadratic equation 3x^2 + 2x - 1 = 0. The roots of a quadratic equation ax^2 + bx + c = 0 can be calculated using the formula:\\n\\nx = [-b ± sqrt(b^2 - 4ac)] / 2a\\n\\nLet\\'s calculate the roots using the Python_REPL tool.\\nObservation: Invalid Format: Missing \\'Action:\\' after \\'Thought:\\'\\nThought: I need to use the Python_REPL tool to calculate the roots of the quadratic equation. The coefficients of the equation are a=3, b=2, and c=-1. I will use the quadratic formula to find the roots. The quadratic formula is x = [-b ± sqrt(b^2 - 4ac)] / 2a.\\nObservation: Invalid Format: Missing \\'Action:\\' after \\'Thought:\\'\\nThought: \\n', 'role': 'user'}], 'model': 'gpt-4', 'stop': ['\\nObservation'], 'stream': True, 'temperature': 0.0}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mI need to use the Python_REPL tool to calculate the roots of the quadratic equation. The coefficients of the equation are a=3, b=2, and c=-1. I will use the quadratic formula to find the roots. The quadratic formula is x = [-b ± sqrt(b^2 - 4ac)] / 2a.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Sep 2025 17:31:48 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'ipv-p3uuox'), (b'openai-processing-ms', b'468'), (b'openai-project', b'proj_voBSgQh5Xdl46y0VcbQ4BGbR'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'504'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'3047'), (b'x-ratelimit-reset-requests', b'1m28.481s'), (b'x-ratelimit-reset-tokens', b'41.716s'), (b'x-request-id', b'req_c583d80fc76e497db69f082976974a5e'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98230efa896bf837-MAN'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sat, 20 Sep 2025 17:31:48 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'ipv-p3uuox', 'openai-processing-ms': '468', 'openai-project': 'proj_voBSgQh5Xdl46y0VcbQ4BGbR', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '504', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '3047', 'x-ratelimit-reset-requests': '1m28.481s', 'x-ratelimit-reset-tokens': '41.716s', 'x-request-id': 'req_c583d80fc76e497db69f082976974a5e', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '98230efa896bf837-MAN', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
            "DEBUG:openai._base_client:request_id: req_c583d80fc76e497db69f082976974a5e\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-cff431c2-1dc4-48fa-b1bd-1aebc7738ec9', 'json_data': {'messages': [{'content': '\\nYou are an assistant with access to tools. When using the write_file tool, you MUST use this exact format:\\n\\nAction: write_file\\nAction Input: {\"file_path\": \"full/path/to/file\", \"text\": \"content to write\"}\\n\\nNever use code blocks, never use variables in the JSON, always use literal string values.\\n\\nTools available: Python_REPL - A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\nterminal - Run shell commands on this Windows machine.\\ncopy_file - Create a copy of a file in a specified location\\nfile_delete - Delete a file\\nfile_search - Recursively search for files in a subdirectory that match the regex pattern\\nmove_file - Move or rename a file from one location to another\\nread_file - Read file from disk\\nwrite_file - Write file to disk\\nlist_directory - List files and directories in a specified folder\\nTool names: Python_REPL, terminal, copy_file, file_delete, file_search, move_file, read_file, write_file, list_directory\\n\\nQuestion: Calculate the roots of 3x^2 + 2x - 1. Then use the write_file tool with this EXACT format (no code blocks, no quotes around the JSON):\\n\\nAction: write_file\\nAction Input: {\"file_path\": \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\quadratic_results.txt\", \"text\": \"Your calculated explanation here\"}\\n\\nDo NOT wrap the Action Input in ```json``` code blocks. Just use plain JSON. Ensure that the json key and value are wrapped in double quotes not single quotes\\nThought: I should think about what needs to be done\\nFirst, we need to calculate the roots of the quadratic equation 3x^2 + 2x - 1 = 0. The roots of a quadratic equation ax^2 + bx + c = 0 can be calculated using the formula:\\n\\nx = [-b ± sqrt(b^2 - 4ac)] / 2a\\n\\nLet\\'s calculate the roots using the Python_REPL tool.\\nObservation: Invalid Format: Missing \\'Action:\\' after \\'Thought:\\'\\nThought: I need to use the Python_REPL tool to calculate the roots of the quadratic equation. The coefficients of the equation are a=3, b=2, and c=-1. I will use the quadratic formula to find the roots. The quadratic formula is x = [-b ± sqrt(b^2 - 4ac)] / 2a.\\nObservation: Invalid Format: Missing \\'Action:\\' after \\'Thought:\\'\\nThought: I need to use the Python_REPL tool to calculate the roots of the quadratic equation. The coefficients of the equation are a=3, b=2, and c=-1. I will use the quadratic formula to find the roots. The quadratic formula is x = [-b ± sqrt(b^2 - 4ac)] / 2a. \\n\\nAction: Python_REPL\\nAction Input: \\nimport math\\na = 3\\nb = 2\\nc = -1\\nroot1 = (-b + math.sqrt(b**2 - 4*a*c)) / (2*a)\\nroot2 = (-b - math.sqrt(b**2 - 4*a*c)) / (2*a)\\nprint(root1, root2)\\nObservation: 0.3333333333333333 -1.0\\n\\nThought: \\n', 'role': 'user'}], 'model': 'gpt-4', 'stop': ['\\nObservation'], 'stream': True, 'temperature': 0.0}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mI need to use the Python_REPL tool to calculate the roots of the quadratic equation. The coefficients of the equation are a=3, b=2, and c=-1. I will use the quadratic formula to find the roots. The quadratic formula is x = [-b ± sqrt(b^2 - 4ac)] / 2a. \n",
            "\n",
            "Action: Python_REPL\n",
            "Action Input: \n",
            "import math\n",
            "a = 3\n",
            "b = 2\n",
            "c = -1\n",
            "root1 = (-b + math.sqrt(b**2 - 4*a*c)) / (2*a)\n",
            "root2 = (-b - math.sqrt(b**2 - 4*a*c)) / (2*a)\n",
            "print(root1, root2)\u001b[0m\u001b[36;1m\u001b[1;3m0.3333333333333333 -1.0\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Sep 2025 17:31:53 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'ipv-p3uuox'), (b'openai-processing-ms', b'745'), (b'openai-project', b'proj_voBSgQh5Xdl46y0VcbQ4BGbR'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'779'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'2827'), (b'x-ratelimit-reset-requests', b'1m33.1s'), (b'x-ratelimit-reset-tokens', b'43.034s'), (b'x-request-id', b'req_dc43ea1e40624c3ba4c8c6386429f24f'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98230f139a8cf837-MAN'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sat, 20 Sep 2025 17:31:53 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'ipv-p3uuox', 'openai-processing-ms': '745', 'openai-project': 'proj_voBSgQh5Xdl46y0VcbQ4BGbR', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '779', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '2827', 'x-ratelimit-reset-requests': '1m33.1s', 'x-ratelimit-reset-tokens': '43.034s', 'x-request-id': 'req_dc43ea1e40624c3ba4c8c6386429f24f', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '98230f139a8cf837-MAN', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
            "DEBUG:openai._base_client:request_id: req_dc43ea1e40624c3ba4c8c6386429f24f\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mThe roots of the equation 3x^2 + 2x - 1 = 0 are 0.333 and -1.0. Now, I will write these results to a file using the write_file tool. The file path is \"C:\\Users\\peter\\Documents\\AgentPlaygroundTest\\quadratic_results.txt\".\n",
            "\n",
            "Action: write_file\n",
            "Action Input: {\"file_path\": \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\quadratic_results.txt\", \"text\": \"The roots of the equation 3x^2 + 2x - 1 = 0 are 0.333 and -1.0.\"}\u001b[0m"
          ]
        },
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for WriteFileInput\ntext\n  Field required [type=missing, input_value={'file_path': '{\"file_pat... are 0.333 and -1.0.\"}'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent_executor_custom\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[33;43mCalculate the roots of 3x^2 + 2x - 1. Then use the write_file tool with this EXACT format (no code blocks, no quotes around the JSON):\u001b[39;49m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[33;43mAction: write_file\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[33;43mAction Input: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mpeter\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mDocuments\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mAgentPlaygroundTest\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mquadratic_results.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYour calculated explanation here\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m}\u001b[39;49m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[33;43mDo NOT wrap the Action Input in ```json``` code blocks. Just use plain JSON. Ensure that the json key and value are wrapped in double quotes not single quotes\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1334\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1408\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1406\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[32m   1407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[32m-> \u001b[39m\u001b[32m1408\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1413\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1433\u001b[39m, in \u001b[36mAgentExecutor._perform_agent_action\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[39m\n\u001b[32m   1431\u001b[39m         tool_run_kwargs[\u001b[33m\"\u001b[39m\u001b[33mllm_prefix\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1432\u001b[39m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     observation = \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1441\u001b[39m     tool_run_kwargs = \u001b[38;5;28mself\u001b[39m._action_agent.tool_run_logging_kwargs()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:892\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    891\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    893\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    894\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:854\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    852\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    858\u001b[39m         tool_kwargs |= {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:769\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    762\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    763\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    766\u001b[39m ):\n\u001b[32m    767\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    768\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:650\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    648\u001b[39m key_ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(get_fields(input_args).keys()))\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModel):\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m     \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n\u001b[32m    652\u001b[39m     input_args.parse_obj({key_: tool_input})\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\langchain-13-min\\.venv\\Lib\\site-packages\\pydantic\\main.py:705\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    701\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    702\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    703\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mValidationError\u001b[39m: 1 validation error for WriteFileInput\ntext\n  Field required [type=missing, input_value={'file_path': '{\"file_pat... are 0.333 and -1.0.\"}'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"
          ]
        }
      ],
      "source": [
        "agent_executor_custom.invoke({\n",
        "    \"input\": \"\"\"Calculate the roots of 3x^2 + 2x - 1. Then use the write_file tool with this EXACT format (no code blocks, no quotes around the JSON):\n",
        "\n",
        "Action: write_file\n",
        "Action Input: {\"file_path\": \"C:\\\\Users\\\\peter\\\\Documents\\\\AgentPlaygroundTest\\\\quadratic_results.txt\", \"text\": \"Your calculated explanation here\"}\n",
        "\n",
        "Do NOT wrap the Action Input in ```json``` code blocks. Just use plain JSON. Ensure that the json key and value are wrapped in double quotes not single quotes\"\"\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "langchain-13-min",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
